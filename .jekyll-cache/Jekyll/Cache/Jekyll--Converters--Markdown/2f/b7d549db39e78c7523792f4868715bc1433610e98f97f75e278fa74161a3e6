I"!<p>Existing GenAttack is a state-of-the-art methods on fooling deep learning based image classifier in black-box setting. However, it still requires probability after softmax layer for adversarial samples selection. In this work, we extend the GenAttack to hard-label case. With an appropriate amount of queries to the TOP-1 class label, the GenAttack can attack the Inception based image classifier on ImageNet.</p>

<p><img src="/assets/images/hard-label.png" alt="Fooling the image classifier by classifying squirrel as parking meter" /></p>
:ET